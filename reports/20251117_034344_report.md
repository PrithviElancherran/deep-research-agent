# Deep Research Report

**Query:** Summarize the current state of regulation around AI safety in the EU.

**Overview**  
The European Union (EU) has recently made significant strides in regulating artificial intelligence (AI) safety through the adoption of the EU AI Act in May 2024. This legislation represents one of the first comprehensive, cross-sectoral regulatory frameworks aimed at ensuring AI technologies are safe, secure, and under human control. The regulation is designed to take effect in 2025 and adopts a risk-based approach to AI governance.

**Key Findings**  
- The EU AI Act was unanimously approved by EU Member States in May 2024.  
- It employs a risk-based regulatory framework that categorizes AI applications by their potential risk to safety and fundamental rights.  
- High-risk AI uses are prohibited or subject to strict obligations, while minimal-risk AI applications remain largely unregulated.  
- The Act aims to balance innovation with safety, ensuring AI systems remain under human oversight.  
- The regulation is cross-sectoral, affecting a wide range of AI applications across industries.  
- It establishes new regulatory and enforcement powers for existing EU bodies, including the European Commission.  
- The EU is also actively addressing the regulation of general-purpose AI, reflecting the evolving AI landscape.

**Details**  
The EU AI Act introduces a tiered regulatory system based on the risk profile of AI applications:

1. **Unacceptable Risk**: Certain AI practices deemed unacceptable are outright prohibited. These include AI systems that manipulate human behavior to cause harm or exploit vulnerabilities.  
2. **High Risk**: AI systems classified as high-risk—such as those used in critical infrastructure, education, employment, law enforcement, and biometric identification—face stringent requirements. These include conformity assessments, transparency obligations, and human oversight mandates.  
3. **Limited Risk**: AI applications with limited risk must comply with transparency requirements, such as informing users when they are interacting with AI.  
4. **Minimal Risk**: The majority of AI applications, including AI-enabled video games and spam filters, are considered minimal risk and are not subject to specific regulatory requirements.

The Act also emphasizes maintaining human control over AI systems to prevent loss of oversight. It aims to foster trust in AI technologies while mitigating potential harms. The regulatory framework is designed to be adaptive, with ongoing discussions about how to regulate emerging technologies like general-purpose AI.

**Sources**  
1. Rimon Law, "A Brief Overview of AI Regulation in Europe" (https://www.rimonlaw.com/a-brief-overview-of-ai-regulation-in-europe/)  
2. Artificial Intelligence Act High-Level Summary (https://artificialintelligenceact.eu/high-level-summary/)  
3. Software Improvement Group, "A comprehensive EU AI Act Summary [August 2025 update]" (https://www.softwareimprovementgroup.com/eu-ai-act-summary/)  
4. Cimplifi, "The Updated State of AI Regulations for 2025" (https://www.cimplifi.com/resources/the-updated-state-of-ai-regulations-for-2025/)  
5. Brookings Institution, "Regulating general-purpose AI: Areas of convergence and divergence across the EU and the US" (https://www.brookings.edu/articles/regulating-general-purpose-ai-areas-of-convergence-and-divergence-across-the-eu-and-the-us/)  
6. White & Case, "AI Watch: Global regulatory tracker - European Union" (https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-european-union)